{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction ML Aide's purpose is making model management a joy for you! Key Benefits ML Aide is designed and developed to be Enterprise-ready: Identity, security, and integrity as a first-class citizen Diverse: Supports every ML library for complete freedom Transparent: Provided open source for maximum transparency Independent: Runs on every cloud platform or on-premises for complete independence Scalable: Scalable from single user to large enterprises and ready for growing demands Effective: Accelerates MLOps for more focus on what really matters: Your business Key Features Track all relevant information of your machine learning models with ML Aide to manage your model lifecycle from training to retirement. Experiment Tracking: Track parameters, metrics, and artifacts in your machine learning experiments that are organized by single runs. Artifact Management: Attach artifacts like code, configs, or models to your experiment runs and reuse them in your next run. Experiment Lineage: Inspect your experiment with a visualized lineage representing the relationship between all runs and artifacts. Model Staging: Put your models under version control and stage them to obtain transparency and reproducibility in your operations. Run Evaluation: Evaluate your runs by viewing or comparing parameters and metrics to identify the best model for your machine learning product. ML Library Integration: An increasing number of integrated machine learning libraries for convenient in-code tracking of parameters, metrics, and models. Access Management: Manage access to your machine learning projects and collaborate with other members of your team. Getting Started Run ML Aide in your local environment. Start Now Tutorial Walk through the model development process with ML Aide. View Tutorial Essentials Learn the essentials of ML Aide. Learn More API Reference Explore the Python SDK or REST API Reference. Explore API Reference","title":"Introduction"},{"location":"#introduction","text":"ML Aide's purpose is making model management a joy for you!","title":"Introduction"},{"location":"#key-benefits","text":"ML Aide is designed and developed to be Enterprise-ready: Identity, security, and integrity as a first-class citizen Diverse: Supports every ML library for complete freedom Transparent: Provided open source for maximum transparency Independent: Runs on every cloud platform or on-premises for complete independence Scalable: Scalable from single user to large enterprises and ready for growing demands Effective: Accelerates MLOps for more focus on what really matters: Your business","title":"Key Benefits"},{"location":"#key-features","text":"Track all relevant information of your machine learning models with ML Aide to manage your model lifecycle from training to retirement. Experiment Tracking: Track parameters, metrics, and artifacts in your machine learning experiments that are organized by single runs. Artifact Management: Attach artifacts like code, configs, or models to your experiment runs and reuse them in your next run. Experiment Lineage: Inspect your experiment with a visualized lineage representing the relationship between all runs and artifacts. Model Staging: Put your models under version control and stage them to obtain transparency and reproducibility in your operations. Run Evaluation: Evaluate your runs by viewing or comparing parameters and metrics to identify the best model for your machine learning product. ML Library Integration: An increasing number of integrated machine learning libraries for convenient in-code tracking of parameters, metrics, and models. Access Management: Manage access to your machine learning projects and collaborate with other members of your team.","title":"Key Features"},{"location":"#getting-started","text":"Run ML Aide in your local environment. Start Now","title":"Getting Started"},{"location":"#tutorial","text":"Walk through the model development process with ML Aide. View Tutorial","title":"Tutorial"},{"location":"#essentials","text":"Learn the essentials of ML Aide. Learn More","title":"Essentials"},{"location":"#api-reference","text":"Explore the Python SDK or REST API Reference. Explore API Reference","title":"API Reference"},{"location":"api-reference/python-sdk/","text":"Python SDK MLAideClient This is the main entry point to use this library. Creates a connection to the ML Aide server and provides read and write access to all resources. __init__ ( self , project_key , options = None ) special Creates a new instance of this class. Parameters: Name Type Description Default project_key str The key of the project, that should be accessed. All operations will be made on this project. required options ConnectionOptions Optional options that will be used to establish a connection. None Source code in mlaide/client.py def __init__ ( self , project_key : str , options : ConnectionOptions = None ): \"\"\"Creates a new instance of this class. Arguments: project_key: The key of the project, that should be accessed. All operations will be made on this project. options: Optional options that will be used to establish a connection. \"\"\" if project_key is None : raise ValueError ( \"project key must be not None\" ) self . __project_key = project_key if options is None : self . __options = MLAideClient . __get_default_options () else : self . __options = MLAideClient . __merge_options ( MLAideClient . __get_default_options (), options ) self . __api_client = AuthenticatedClient ( base_url = self . __options . server_url , api_key = self . __options . api_key ) get_artifact ( self , name , version ) Gets an existing artifact. The artifact is specified by its name and version. If no version is specified, the latest available version of the artifact will be used. Parameters: Name Type Description Default name str The name of the artifact. required version Optional[int] The (optional) version of the artifact. If no version is specified, the latest available version required Returns: Type Description ActiveArtifact This object encapsulates an artifact and provides functions to interact with the artifact. Source code in mlaide/client.py def get_artifact ( self , name : str , version : Optional [ int ]) -> ActiveArtifact : \"\"\"Gets an existing artifact. The artifact is specified by its name and version. If no version is specified, the latest available version of the artifact will be used. Arguments: name: The name of the artifact. version: The (optional) version of the artifact. If no version is specified, the latest available version will be loaded. Returns: This object encapsulates an artifact and provides functions to interact with the artifact. \"\"\" return ActiveArtifact ( self . __api_client , self . __project_key , name , version ) load_model ( self , name , version = None , stage = None ) Loads and restores a model. The model is specified by its name and version. If no version is specified, the latest available version of the model will be used. Parameters: Name Type Description Default name str The name of the model. required version Optional[int] The (optional) version of the model. If no version is specified, the latest available version None stage Optional[ModelStage] This argument can only be used when version is None. In this case the latest model can be filtered None Returns: Type Description any The model. E.g. in the case of a scikit-learn model the return value will be a deserialized model that can be used for predictions using .predict(...) . Source code in mlaide/client.py def load_model ( self , name : str , version : Optional [ int ] = None , stage : Optional [ ModelStage ] = None ) -> any : \"\"\"Loads and restores a model. The model is specified by its name and version. If no version is specified, the latest available version of the model will be used. Arguments: name: The name of the model. version: The (optional) version of the model. If no version is specified, the latest available version will be loaded. stage: This argument can only be used when version is None. In this case the latest model can be filtered by its stage. In reverse this means that all model versions will be ignored when they have not the specified stage. Returns: The model. E.g. in the case of a scikit-learn model the return value will be a deserialized model that can be used for predictions using `.predict(...)`. \"\"\" if version is not None and stage is not None : raise ValueError ( \"Only one argument of version and stage can be not None\" ) return ActiveArtifact ( self . __api_client , self . __project_key , name , version , stage ) . load_model () start_new_run ( self , experiment_key = None , run_name = None , used_artifacts = None , auto_create_experiment = True ) Creates and starts a new run, that will be assigned to the specified experiment. The run object can be used to log all necessary information. Parameters: Name Type Description Default experiment_key str The key of the experiment, that the new run should be assigned to. If None a new, random None run_name str The name of the run. The name helps to identify the run for humans. If None a random name will None used_artifacts List[ArtifactRef] An optional list of ArtifactRef that references artifacts, that are used as input for None auto_create_experiment bool Specifies whether the experiment (see experiment_key ) should be created if it True Returns: Type Description ActiveRun This object encapsulates the newly created run and provides functions to log all information that belongs to the run. Source code in mlaide/client.py def start_new_run ( self , experiment_key : str = None , run_name : str = None , used_artifacts : List [ ArtifactRef ] = None , auto_create_experiment : bool = True ) -> ActiveRun : \"\"\"Creates and starts a new run, that will be assigned to the specified experiment. The run object can be used to log all necessary information. Arguments: experiment_key: The key of the experiment, that the new run should be assigned to. If `None` a new, random experiment will be created. run_name: The name of the run. The name helps to identify the run for humans. If `None` a random name will be used. used_artifacts: An optional list of `ArtifactRef` that references artifacts, that are used as input for this run. This information will help to create and visualize the experiment lineage. auto_create_experiment: Specifies whether the experiment (see `experiment_key`) should be created if it does not exist or not. If `auto_create_experiment` is `False` and the experiment does not exist an error will be raised. Returns: This object encapsulates the newly created run and provides functions to log all information \\ that belongs to the run. \"\"\" return ActiveRun ( self . __api_client , self . __project_key , experiment_key , run_name , used_artifacts , auto_create_experiment ) Active Run This class provides access to runs that are stored in ML Aide add_artifact_file ( self , artifact , file , filename = None ) Add a file to an existing artifact. To add multiple file, specify a directory or invoke this function multiple times. Parameters: Name Type Description Default artifact Artifact The artifact to which the file should be added. required file Union[str, _io.BytesIO] The file that should be added. This can be a io.BytesIO object or a string to a file or directory. required filename str The filename. If the file is of type BytesIO the filename must be specified. If the file is a string, the original filename will be the default. None Source code in mlaide/active_run.py def add_artifact_file ( self , artifact : Artifact , file : Union [ str , BytesIO ], filename : str = None ): \"\"\"Add a file to an existing artifact. To add multiple file, specify a directory or invoke this function multiple times. Arguments: artifact: The artifact to which the file should be added. file: The file that should be added. This can be a io.BytesIO object or a string to a file or directory. filename: The filename. If the file is of type BytesIO the filename must be specified. If the file is a string, the original filename will be the default. \"\"\" artifact_api . upload_file ( client = self . __api_client , project_key = self . __project_key , artifact_name = artifact . name , artifact_version = artifact . version , filename = filename if filename is not None else ActiveRun . __extract_filename ( file ), file = ActiveRun . __normalize_file ( file )) create_artifact ( self , name , artifact_type , metadata ) Creates a new artifact. If an artifact with the same name already exists, a new artifact with the next available version number will be registered. Parameters: Name Type Description Default name str The name of the artifact. required artifact_type str The artifact type. required metadata Optional[Dict[str, str]] Some optional metadata that will be attached to the artifact. required Source code in mlaide/active_run.py def create_artifact ( self , name : str , artifact_type : str , metadata : Optional [ Dict [ str , str ]]) -> Artifact : \"\"\"Creates a new artifact. If an artifact with the same name already exists, a new artifact with the next available version number will be registered. Arguments: name: The name of the artifact. artifact_type: The artifact type. metadata: Some optional metadata that will be attached to the artifact. \"\"\" artifact_dto = ArtifactDto ( name = name , type = artifact_type , metadata = metadata , run_key = self . __run . key ) artifact_dto = artifact_api . create_artifact ( client = self . __api_client , project_key = self . __project_key , artifact = artifact_dto ) return dto_to_artifact ( artifact_dto ) log_metric ( self , key , value ) Logs a metric Parameters: Name Type Description Default key str The key of the metric. required value The value of the metric. The value can be any type that is JSON serializable. required Source code in mlaide/active_run.py def log_metric ( self , key : str , value ) -> Run : \"\"\"Logs a metric Arguments: key: The key of the metric. value: The value of the metric. The value can be any type that is JSON serializable. \"\"\" self . __run . metrics [ key ] = value run_api . update_run_metrics ( client = self . __api_client , project_key = self . __project_key , run_key = self . __run . key , metrics = { key : value }) return self . __run log_model ( self , model , model_name , metadata = None ) Creates a new artifact with type 'model'. The artifact will be registered as model. Parameters: Name Type Description Default model The model. The model must be serializable. required model_name str The name of the model. The name will be used as artifact filename. required metadata Optional[Dict[str, str]] Some optional metadata that will be attached to the artifact. None Source code in mlaide/active_run.py def log_model ( self , model , model_name : str , metadata : Optional [ Dict [ str , str ]] = None ): \"\"\"Creates a new artifact with type 'model'. The artifact will be registered as model. Arguments: model: The model. The model must be serializable. model_name: The name of the model. The name will be used as artifact filename. metadata: Some optional metadata that will be attached to the artifact. \"\"\" serialized_model = _model_deser . serialize ( model ) artifact = self . create_artifact ( name = model_name , artifact_type = 'model' , metadata = metadata ) self . add_artifact_file ( artifact = artifact , file = serialized_model , filename = 'model.pkl' ) artifact_api . create_model ( client = self . __api_client , project_key = self . __project_key , artifact_name = artifact . name , artifact_version = artifact . version ) log_parameter ( self , key , value ) Logs a parameter Parameters: Name Type Description Default key str The key of the parameter. required value The value of the parameter. The value must be a scalar value (e.g. string, int, float, ...). required Source code in mlaide/active_run.py def log_parameter ( self , key : str , value ) -> Run : \"\"\"Logs a parameter Arguments: key: The key of the parameter. value: The value of the parameter. The value must be a scalar value (e.g. string, int, float, ...). \"\"\" self . __run . parameters [ key ] = value run_api . update_run_parameters ( client = self . __api_client , project_key = self . __project_key , run_key = self . __run . key , parameters = { key : value }) return self . __run set_completed_status ( self ) Sets the status of the current run as completed. Source code in mlaide/active_run.py def set_completed_status ( self ) -> Run : \"\"\"Sets the status of the current run as completed.\"\"\" return self . _set_status ( RunStatus . COMPLETED ) set_failed_status ( self ) Sets the status of the current run as failed. Source code in mlaide/active_run.py def set_failed_status ( self ) -> Run : \"\"\"Sets the status of the current run as failed.\"\"\" return self . _set_status ( RunStatus . FAILED ) Active Artifact This class provides access to artifacts that are stored in ML Aide download ( self , target_directory ) Downloads all files of this artifact and stores them into the specified directory. Parameters: Name Type Description Default target_directory str The path to the directory where all files should be stored. required Source code in mlaide/active_artifact.py def download ( self , target_directory : str ): \"\"\"Downloads all files of this artifact and stores them into the specified directory. Arguments: target_directory: The path to the directory where all files should be stored. \"\"\" # download artifact_bytes , artifact_filename = self . __download_zip () # unzip and write to disk with ZipFile ( artifact_bytes ) as z : z . extractall ( target_directory ) load ( self , filename ) Load a specific file of this artifact into memory Parameters: Name Type Description Default filename str The name of the file that should be loaded required Source code in mlaide/active_artifact.py def load ( self , filename : str ) -> BytesIO : \"\"\"Load a specific file of this artifact into memory Arguments: filename: The name of the file that should be loaded \"\"\" # TODO: Do not download whole zip; instead download just the single file zip_bytes , zip_filename = self . __download_zip () with ZipFile ( zip_bytes ) as z : zip_info = z . infolist () desired_file = next ( info for info in zip_info if info . filename == filename ) with z . open ( desired_file , 'r' ) as zip_file : return BytesIO ( zip_file . read ())","title":"Python SDK"},{"location":"api-reference/python-sdk/#python-sdk","text":"","title":"Python SDK"},{"location":"api-reference/python-sdk/#mlaideclient","text":"This is the main entry point to use this library. Creates a connection to the ML Aide server and provides read and write access to all resources.","title":"MLAideClient"},{"location":"api-reference/python-sdk/#mlaide.client.MLAideClient.__init__","text":"Creates a new instance of this class. Parameters: Name Type Description Default project_key str The key of the project, that should be accessed. All operations will be made on this project. required options ConnectionOptions Optional options that will be used to establish a connection. None Source code in mlaide/client.py def __init__ ( self , project_key : str , options : ConnectionOptions = None ): \"\"\"Creates a new instance of this class. Arguments: project_key: The key of the project, that should be accessed. All operations will be made on this project. options: Optional options that will be used to establish a connection. \"\"\" if project_key is None : raise ValueError ( \"project key must be not None\" ) self . __project_key = project_key if options is None : self . __options = MLAideClient . __get_default_options () else : self . __options = MLAideClient . __merge_options ( MLAideClient . __get_default_options (), options ) self . __api_client = AuthenticatedClient ( base_url = self . __options . server_url , api_key = self . __options . api_key )","title":"__init__()"},{"location":"api-reference/python-sdk/#mlaide.client.MLAideClient.get_artifact","text":"Gets an existing artifact. The artifact is specified by its name and version. If no version is specified, the latest available version of the artifact will be used. Parameters: Name Type Description Default name str The name of the artifact. required version Optional[int] The (optional) version of the artifact. If no version is specified, the latest available version required Returns: Type Description ActiveArtifact This object encapsulates an artifact and provides functions to interact with the artifact. Source code in mlaide/client.py def get_artifact ( self , name : str , version : Optional [ int ]) -> ActiveArtifact : \"\"\"Gets an existing artifact. The artifact is specified by its name and version. If no version is specified, the latest available version of the artifact will be used. Arguments: name: The name of the artifact. version: The (optional) version of the artifact. If no version is specified, the latest available version will be loaded. Returns: This object encapsulates an artifact and provides functions to interact with the artifact. \"\"\" return ActiveArtifact ( self . __api_client , self . __project_key , name , version )","title":"get_artifact()"},{"location":"api-reference/python-sdk/#mlaide.client.MLAideClient.load_model","text":"Loads and restores a model. The model is specified by its name and version. If no version is specified, the latest available version of the model will be used. Parameters: Name Type Description Default name str The name of the model. required version Optional[int] The (optional) version of the model. If no version is specified, the latest available version None stage Optional[ModelStage] This argument can only be used when version is None. In this case the latest model can be filtered None Returns: Type Description any The model. E.g. in the case of a scikit-learn model the return value will be a deserialized model that can be used for predictions using .predict(...) . Source code in mlaide/client.py def load_model ( self , name : str , version : Optional [ int ] = None , stage : Optional [ ModelStage ] = None ) -> any : \"\"\"Loads and restores a model. The model is specified by its name and version. If no version is specified, the latest available version of the model will be used. Arguments: name: The name of the model. version: The (optional) version of the model. If no version is specified, the latest available version will be loaded. stage: This argument can only be used when version is None. In this case the latest model can be filtered by its stage. In reverse this means that all model versions will be ignored when they have not the specified stage. Returns: The model. E.g. in the case of a scikit-learn model the return value will be a deserialized model that can be used for predictions using `.predict(...)`. \"\"\" if version is not None and stage is not None : raise ValueError ( \"Only one argument of version and stage can be not None\" ) return ActiveArtifact ( self . __api_client , self . __project_key , name , version , stage ) . load_model ()","title":"load_model()"},{"location":"api-reference/python-sdk/#mlaide.client.MLAideClient.start_new_run","text":"Creates and starts a new run, that will be assigned to the specified experiment. The run object can be used to log all necessary information. Parameters: Name Type Description Default experiment_key str The key of the experiment, that the new run should be assigned to. If None a new, random None run_name str The name of the run. The name helps to identify the run for humans. If None a random name will None used_artifacts List[ArtifactRef] An optional list of ArtifactRef that references artifacts, that are used as input for None auto_create_experiment bool Specifies whether the experiment (see experiment_key ) should be created if it True Returns: Type Description ActiveRun This object encapsulates the newly created run and provides functions to log all information that belongs to the run. Source code in mlaide/client.py def start_new_run ( self , experiment_key : str = None , run_name : str = None , used_artifacts : List [ ArtifactRef ] = None , auto_create_experiment : bool = True ) -> ActiveRun : \"\"\"Creates and starts a new run, that will be assigned to the specified experiment. The run object can be used to log all necessary information. Arguments: experiment_key: The key of the experiment, that the new run should be assigned to. If `None` a new, random experiment will be created. run_name: The name of the run. The name helps to identify the run for humans. If `None` a random name will be used. used_artifacts: An optional list of `ArtifactRef` that references artifacts, that are used as input for this run. This information will help to create and visualize the experiment lineage. auto_create_experiment: Specifies whether the experiment (see `experiment_key`) should be created if it does not exist or not. If `auto_create_experiment` is `False` and the experiment does not exist an error will be raised. Returns: This object encapsulates the newly created run and provides functions to log all information \\ that belongs to the run. \"\"\" return ActiveRun ( self . __api_client , self . __project_key , experiment_key , run_name , used_artifacts , auto_create_experiment )","title":"start_new_run()"},{"location":"api-reference/python-sdk/#active-run","text":"This class provides access to runs that are stored in ML Aide","title":"Active Run"},{"location":"api-reference/python-sdk/#mlaide.active_run.ActiveRun.add_artifact_file","text":"Add a file to an existing artifact. To add multiple file, specify a directory or invoke this function multiple times. Parameters: Name Type Description Default artifact Artifact The artifact to which the file should be added. required file Union[str, _io.BytesIO] The file that should be added. This can be a io.BytesIO object or a string to a file or directory. required filename str The filename. If the file is of type BytesIO the filename must be specified. If the file is a string, the original filename will be the default. None Source code in mlaide/active_run.py def add_artifact_file ( self , artifact : Artifact , file : Union [ str , BytesIO ], filename : str = None ): \"\"\"Add a file to an existing artifact. To add multiple file, specify a directory or invoke this function multiple times. Arguments: artifact: The artifact to which the file should be added. file: The file that should be added. This can be a io.BytesIO object or a string to a file or directory. filename: The filename. If the file is of type BytesIO the filename must be specified. If the file is a string, the original filename will be the default. \"\"\" artifact_api . upload_file ( client = self . __api_client , project_key = self . __project_key , artifact_name = artifact . name , artifact_version = artifact . version , filename = filename if filename is not None else ActiveRun . __extract_filename ( file ), file = ActiveRun . __normalize_file ( file ))","title":"add_artifact_file()"},{"location":"api-reference/python-sdk/#mlaide.active_run.ActiveRun.create_artifact","text":"Creates a new artifact. If an artifact with the same name already exists, a new artifact with the next available version number will be registered. Parameters: Name Type Description Default name str The name of the artifact. required artifact_type str The artifact type. required metadata Optional[Dict[str, str]] Some optional metadata that will be attached to the artifact. required Source code in mlaide/active_run.py def create_artifact ( self , name : str , artifact_type : str , metadata : Optional [ Dict [ str , str ]]) -> Artifact : \"\"\"Creates a new artifact. If an artifact with the same name already exists, a new artifact with the next available version number will be registered. Arguments: name: The name of the artifact. artifact_type: The artifact type. metadata: Some optional metadata that will be attached to the artifact. \"\"\" artifact_dto = ArtifactDto ( name = name , type = artifact_type , metadata = metadata , run_key = self . __run . key ) artifact_dto = artifact_api . create_artifact ( client = self . __api_client , project_key = self . __project_key , artifact = artifact_dto ) return dto_to_artifact ( artifact_dto )","title":"create_artifact()"},{"location":"api-reference/python-sdk/#mlaide.active_run.ActiveRun.log_metric","text":"Logs a metric Parameters: Name Type Description Default key str The key of the metric. required value The value of the metric. The value can be any type that is JSON serializable. required Source code in mlaide/active_run.py def log_metric ( self , key : str , value ) -> Run : \"\"\"Logs a metric Arguments: key: The key of the metric. value: The value of the metric. The value can be any type that is JSON serializable. \"\"\" self . __run . metrics [ key ] = value run_api . update_run_metrics ( client = self . __api_client , project_key = self . __project_key , run_key = self . __run . key , metrics = { key : value }) return self . __run","title":"log_metric()"},{"location":"api-reference/python-sdk/#mlaide.active_run.ActiveRun.log_model","text":"Creates a new artifact with type 'model'. The artifact will be registered as model. Parameters: Name Type Description Default model The model. The model must be serializable. required model_name str The name of the model. The name will be used as artifact filename. required metadata Optional[Dict[str, str]] Some optional metadata that will be attached to the artifact. None Source code in mlaide/active_run.py def log_model ( self , model , model_name : str , metadata : Optional [ Dict [ str , str ]] = None ): \"\"\"Creates a new artifact with type 'model'. The artifact will be registered as model. Arguments: model: The model. The model must be serializable. model_name: The name of the model. The name will be used as artifact filename. metadata: Some optional metadata that will be attached to the artifact. \"\"\" serialized_model = _model_deser . serialize ( model ) artifact = self . create_artifact ( name = model_name , artifact_type = 'model' , metadata = metadata ) self . add_artifact_file ( artifact = artifact , file = serialized_model , filename = 'model.pkl' ) artifact_api . create_model ( client = self . __api_client , project_key = self . __project_key , artifact_name = artifact . name , artifact_version = artifact . version )","title":"log_model()"},{"location":"api-reference/python-sdk/#mlaide.active_run.ActiveRun.log_parameter","text":"Logs a parameter Parameters: Name Type Description Default key str The key of the parameter. required value The value of the parameter. The value must be a scalar value (e.g. string, int, float, ...). required Source code in mlaide/active_run.py def log_parameter ( self , key : str , value ) -> Run : \"\"\"Logs a parameter Arguments: key: The key of the parameter. value: The value of the parameter. The value must be a scalar value (e.g. string, int, float, ...). \"\"\" self . __run . parameters [ key ] = value run_api . update_run_parameters ( client = self . __api_client , project_key = self . __project_key , run_key = self . __run . key , parameters = { key : value }) return self . __run","title":"log_parameter()"},{"location":"api-reference/python-sdk/#mlaide.active_run.ActiveRun.set_completed_status","text":"Sets the status of the current run as completed. Source code in mlaide/active_run.py def set_completed_status ( self ) -> Run : \"\"\"Sets the status of the current run as completed.\"\"\" return self . _set_status ( RunStatus . COMPLETED )","title":"set_completed_status()"},{"location":"api-reference/python-sdk/#mlaide.active_run.ActiveRun.set_failed_status","text":"Sets the status of the current run as failed. Source code in mlaide/active_run.py def set_failed_status ( self ) -> Run : \"\"\"Sets the status of the current run as failed.\"\"\" return self . _set_status ( RunStatus . FAILED )","title":"set_failed_status()"},{"location":"api-reference/python-sdk/#active-artifact","text":"This class provides access to artifacts that are stored in ML Aide","title":"Active Artifact"},{"location":"api-reference/python-sdk/#mlaide.active_artifact.ActiveArtifact.download","text":"Downloads all files of this artifact and stores them into the specified directory. Parameters: Name Type Description Default target_directory str The path to the directory where all files should be stored. required Source code in mlaide/active_artifact.py def download ( self , target_directory : str ): \"\"\"Downloads all files of this artifact and stores them into the specified directory. Arguments: target_directory: The path to the directory where all files should be stored. \"\"\" # download artifact_bytes , artifact_filename = self . __download_zip () # unzip and write to disk with ZipFile ( artifact_bytes ) as z : z . extractall ( target_directory )","title":"download()"},{"location":"api-reference/python-sdk/#mlaide.active_artifact.ActiveArtifact.load","text":"Load a specific file of this artifact into memory Parameters: Name Type Description Default filename str The name of the file that should be loaded required Source code in mlaide/active_artifact.py def load ( self , filename : str ) -> BytesIO : \"\"\"Load a specific file of this artifact into memory Arguments: filename: The name of the file that should be loaded \"\"\" # TODO: Do not download whole zip; instead download just the single file zip_bytes , zip_filename = self . __download_zip () with ZipFile ( zip_bytes ) as z : zip_info = z . infolist () desired_file = next ( info for info in zip_info if info . filename == filename ) with z . open ( desired_file , 'r' ) as zip_file : return BytesIO ( zip_file . read ())","title":"load()"},{"location":"api-reference/rest-api/","text":"REST API const ui = SwaggerUIBundle({ url: 'swagger.yml', dom_id: '#swagger-ui', })","title":"REST API"},{"location":"api-reference/rest-api/#rest-api","text":"const ui = SwaggerUIBundle({ url: 'swagger.yml', dom_id: '#swagger-ui', })","title":"REST API"},{"location":"architecture/","text":"Overview Work in Progress This chapter describes the architectural core concepts of ML Aide.","title":"Overview"},{"location":"architecture/#overview","text":"","title":"Overview"},{"location":"architecture/#work-in-progress","text":"This chapter describes the architectural core concepts of ML Aide.","title":"Work in Progress"},{"location":"essentials/","text":"Overview This chapter describes the essentials of projects, experiments, runs, and their connection with users, artifacts, and models. Projects Projects are at the top hierarchy level and group several experiments that belong to it. Projects represent a business problem that shall be solved with a machine learning model that is created through the underlying experiments. Example Project: House Price Prediction Please see the projects page for further details. Experiments Experiments belong to exactly one project and group several runs that belong to it. Experiments represent an attempt to solve the business problem with the underlying runs that generate several artifacts as well as models. Example Project: House Price Prediction Experiment 1: Linear Regression Experiment 2: Random Forest Regression Experiment 3: Random Forest Regression with HP tuning Please see the experiments page for further details. Runs Runs belong to exactly one project and none, one or many experiments. However, it is good practice to assign a run to at least one experiment. They may have input from previous runs and may generate outputs \u2013 named artifacts \u2013 such as models. Runs also contain parameters and metrics that are key-value pairs to make them comparable. Example Project: House Price Prediction Experiment 1: Linear Regression Run 1: Data Preparation Run 2: Test Train Split Run 3: Linear Regression Training Experiment 2: Random Forest Regression Run 1: Data Preparation Run 2: Test Train Split Run 4: Random Forest Regression Training Please see the runs page for further details. Artifacts Artifacts are generated by runs and may consist of one or a group of files. They have a type that can be freely assigned as well as the artifact name. Example Experiment 1: Linear Regression Run 1: Data Preparation Artifact 1: housing.csv Run 2: Test Train Split Artifact 1: Pipeline Run 3: Linear Regression Training Artifact 2: Model Please see the artifacts page for further details. Models Models are a special type of artifact named model and have a special status in ML Aide since they are the heart of the application. Example Experiment 1: Linear Regression Run 1: Linear Regression Training 1 Artifact 1: Model 1 Run 2: Linear Regression Training 2 Artifact 1: Model 2 Please see the models page for further details. Project Settings Project members can be managed via project settings. The following roles are available: Owner Contributor Viewer Please see the project settings page for further details. Users ML Aide provides internal user management that allows to Update personal information Manage API Keys Please see the users page for further details.","title":"Overview"},{"location":"essentials/#overview","text":"This chapter describes the essentials of projects, experiments, runs, and their connection with users, artifacts, and models.","title":"Overview"},{"location":"essentials/#projects","text":"Projects are at the top hierarchy level and group several experiments that belong to it. Projects represent a business problem that shall be solved with a machine learning model that is created through the underlying experiments. Example Project: House Price Prediction Please see the projects page for further details.","title":"Projects"},{"location":"essentials/#experiments","text":"Experiments belong to exactly one project and group several runs that belong to it. Experiments represent an attempt to solve the business problem with the underlying runs that generate several artifacts as well as models. Example Project: House Price Prediction Experiment 1: Linear Regression Experiment 2: Random Forest Regression Experiment 3: Random Forest Regression with HP tuning Please see the experiments page for further details.","title":"Experiments"},{"location":"essentials/#runs","text":"Runs belong to exactly one project and none, one or many experiments. However, it is good practice to assign a run to at least one experiment. They may have input from previous runs and may generate outputs \u2013 named artifacts \u2013 such as models. Runs also contain parameters and metrics that are key-value pairs to make them comparable. Example Project: House Price Prediction Experiment 1: Linear Regression Run 1: Data Preparation Run 2: Test Train Split Run 3: Linear Regression Training Experiment 2: Random Forest Regression Run 1: Data Preparation Run 2: Test Train Split Run 4: Random Forest Regression Training Please see the runs page for further details.","title":"Runs"},{"location":"essentials/#artifacts","text":"Artifacts are generated by runs and may consist of one or a group of files. They have a type that can be freely assigned as well as the artifact name. Example Experiment 1: Linear Regression Run 1: Data Preparation Artifact 1: housing.csv Run 2: Test Train Split Artifact 1: Pipeline Run 3: Linear Regression Training Artifact 2: Model Please see the artifacts page for further details.","title":"Artifacts"},{"location":"essentials/#models","text":"Models are a special type of artifact named model and have a special status in ML Aide since they are the heart of the application. Example Experiment 1: Linear Regression Run 1: Linear Regression Training 1 Artifact 1: Model 1 Run 2: Linear Regression Training 2 Artifact 1: Model 2 Please see the models page for further details.","title":"Models"},{"location":"essentials/#project-settings","text":"Project members can be managed via project settings. The following roles are available: Owner Contributor Viewer Please see the project settings page for further details.","title":"Project Settings"},{"location":"essentials/#users","text":"ML Aide provides internal user management that allows to Update personal information Manage API Keys Please see the users page for further details.","title":"Users"},{"location":"essentials/artifacts/","text":"Artifacts Overview Artifacts are generated by runs and may consist of one or a group of files. They have a type that can be freely assigned as well as the artifact name. Example Experiment 1: Linear Regression Run 1: Data Preparation Artifact 1: housing.csv Run 2: Test Train Split Artifact 1: Pipeline Run 3: Linear Regression Training Artifact 2: Model Features Show Artifacts Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Artifacts button in the side navigation Create Artifact Instructions Code artifact = run . create_artifact ( name = \"my-dataset\" , artifact_type = \"dataset\" , metadata = {}) run . add_artifact_file ( artifact , 'dataset.csv' )","title":"Artifacts"},{"location":"essentials/artifacts/#artifacts","text":"","title":"Artifacts"},{"location":"essentials/artifacts/#overview","text":"Artifacts are generated by runs and may consist of one or a group of files. They have a type that can be freely assigned as well as the artifact name. Example Experiment 1: Linear Regression Run 1: Data Preparation Artifact 1: housing.csv Run 2: Test Train Split Artifact 1: Pipeline Run 3: Linear Regression Training Artifact 2: Model","title":"Overview"},{"location":"essentials/artifacts/#features","text":"","title":"Features"},{"location":"essentials/artifacts/#show-artifacts","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Artifacts button in the side navigation","title":"Show Artifacts"},{"location":"essentials/artifacts/#create-artifact","text":"Instructions Code artifact = run . create_artifact ( name = \"my-dataset\" , artifact_type = \"dataset\" , metadata = {}) run . add_artifact_file ( artifact , 'dataset.csv' )","title":"Create Artifact"},{"location":"essentials/experiments/","text":"Experiments Overview Experiments belong to exactly one project and group several runs that belong to it. Experiments represent an attempt to solve the business problem with the underlying runs that generate several artifacts as well as models. Example Project: House Price Prediction Experiment 1: Linear Regression Experiment 2: Random Forest Regression Experiment 3: Random Forest Regression with HP tuning Features Show Experiments Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Experiments button in the side navigation Create Experiment Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Experiments button in the side navigation Click the Add Experiment button Provide Experiment name Experiment key Experiment tags - optional Experiment status Confirm by clicking the Create button Edit Experiment Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Experiments button in the side navigation Click the Edit Experiment button ( ) for the relevant experiment Change Experiment name Experiment tags Experiment status Confirm by clicking the Update button Show Details Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Experiments button in the side navigation Click the name of the relevant experiment","title":"Experiments"},{"location":"essentials/experiments/#experiments","text":"","title":"Experiments"},{"location":"essentials/experiments/#overview","text":"Experiments belong to exactly one project and group several runs that belong to it. Experiments represent an attempt to solve the business problem with the underlying runs that generate several artifacts as well as models. Example Project: House Price Prediction Experiment 1: Linear Regression Experiment 2: Random Forest Regression Experiment 3: Random Forest Regression with HP tuning","title":"Overview"},{"location":"essentials/experiments/#features","text":"","title":"Features"},{"location":"essentials/experiments/#show-experiments","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Experiments button in the side navigation","title":"Show Experiments"},{"location":"essentials/experiments/#create-experiment","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Experiments button in the side navigation Click the Add Experiment button Provide Experiment name Experiment key Experiment tags - optional Experiment status Confirm by clicking the Create button","title":"Create Experiment"},{"location":"essentials/experiments/#edit-experiment","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Experiments button in the side navigation Click the Edit Experiment button ( ) for the relevant experiment Change Experiment name Experiment tags Experiment status Confirm by clicking the Update button","title":"Edit Experiment"},{"location":"essentials/experiments/#show-details","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Experiments button in the side navigation Click the name of the relevant experiment","title":"Show Details"},{"location":"essentials/models/","text":"Models Overview Models are a special type of artifact named model and have a special status in ML Aide since they are the heart of the application. Example Experiment 1: Linear Regression Run 1: Linear Regression Training 1 Artifact 1: Model 1 Run 2: Linear Regression Training 2 Artifact 1: Model 2 Show Models Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Models button in the side navigation Create Model Instructions Code lin_reg = LinearRegression () lin_reg . fit ( X_train , y_train ) run . log_model ( lin_reg , model_name = \"linear regression model\" ) Edit Model Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Models button in the side navigation Click the Edit Model button ( ) for the relevant model Change Model stage Note - optional Confirm by clicking the Update button Show Stage Log Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Models button in the side navigation Click the Stage log button ( ) for the relevant model Close by clicking the Close button","title":"Models"},{"location":"essentials/models/#models","text":"","title":"Models"},{"location":"essentials/models/#overview","text":"Models are a special type of artifact named model and have a special status in ML Aide since they are the heart of the application. Example Experiment 1: Linear Regression Run 1: Linear Regression Training 1 Artifact 1: Model 1 Run 2: Linear Regression Training 2 Artifact 1: Model 2","title":"Overview"},{"location":"essentials/models/#show-models","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Models button in the side navigation","title":"Show Models"},{"location":"essentials/models/#create-model","text":"Instructions Code lin_reg = LinearRegression () lin_reg . fit ( X_train , y_train ) run . log_model ( lin_reg , model_name = \"linear regression model\" )","title":"Create Model"},{"location":"essentials/models/#edit-model","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Models button in the side navigation Click the Edit Model button ( ) for the relevant model Change Model stage Note - optional Confirm by clicking the Update button","title":"Edit Model"},{"location":"essentials/models/#show-stage-log","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Models button in the side navigation Click the Stage log button ( ) for the relevant model Close by clicking the Close button","title":"Show Stage Log"},{"location":"essentials/project-settings/","text":"Project Settings Project members can be managed via project settings. The following roles are available: Owner Contributor Viewer Roles & Rights Overview TODO: Check create roles & rights overview as table Features Show Settings Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Settings button in the side navigation Add Project Members Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Settings button in the side navigation Click the Add Project Member button Provide Email Role Confirm by clicking the Create button User has to log in at least once before he/she can be added as a project member Edit Project Members Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Settings button in the side navigation Click the Edit Project Member button ( ) for the relevant project member Change Role Confirm by clicking the Update button","title":"Project Settings"},{"location":"essentials/project-settings/#project-settings","text":"Project members can be managed via project settings. The following roles are available: Owner Contributor Viewer","title":"Project Settings"},{"location":"essentials/project-settings/#roles-rights-overview","text":"TODO: Check create roles & rights overview as table","title":"Roles &amp; Rights Overview"},{"location":"essentials/project-settings/#features","text":"","title":"Features"},{"location":"essentials/project-settings/#show-settings","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Settings button in the side navigation","title":"Show Settings"},{"location":"essentials/project-settings/#add-project-members","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Settings button in the side navigation Click the Add Project Member button Provide Email Role Confirm by clicking the Create button User has to log in at least once before he/she can be added as a project member","title":"Add Project Members"},{"location":"essentials/project-settings/#edit-project-members","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Settings button in the side navigation Click the Edit Project Member button ( ) for the relevant project member Change Role Confirm by clicking the Update button","title":"Edit Project Members"},{"location":"essentials/projects/","text":"Projects Overview Projects are at the top hierarchy level and group several experiments that belong to it. Projects represent a business problem that shall be solved with a machine learning model that is created through the underlying experiments. Example Project: House Price Prediction Features Show Projects Instructions GUI Click the ML Aide button in the upper left corner Or Click the Projects dropdown in the main navigation and click Show all Create Project Instructions GUI Click the ML Aide button in the upper left corner Click the Add Project button Provide Project name Project key Confirm by clicking the Create button","title":"Projects"},{"location":"essentials/projects/#projects","text":"","title":"Projects"},{"location":"essentials/projects/#overview","text":"Projects are at the top hierarchy level and group several experiments that belong to it. Projects represent a business problem that shall be solved with a machine learning model that is created through the underlying experiments. Example Project: House Price Prediction","title":"Overview"},{"location":"essentials/projects/#features","text":"","title":"Features"},{"location":"essentials/projects/#show-projects","text":"Instructions GUI Click the ML Aide button in the upper left corner Or Click the Projects dropdown in the main navigation and click Show all","title":"Show Projects"},{"location":"essentials/projects/#create-project","text":"Instructions GUI Click the ML Aide button in the upper left corner Click the Add Project button Provide Project name Project key Confirm by clicking the Create button","title":"Create Project"},{"location":"essentials/runs/","text":"Runs Overview Runs belong to exactly one project and none, one or many experiments. However, it is good practice to assign a run to at least one experiment. They may have input from previous runs and may generate outputs \u2013 named artifacts \u2013 such as models. Runs also contain parameters and metrics that are key-value pairs to make them comparable. Example Project: House Price Prediction Experiment 1: Linear Regression Run 1: Data Preparation Run 2: Test Train Split Run 3: Linear Regression Training Experiment 2: Random Forest Regression Run 1: Data Preparation Run 2: Test Train Split Run 4: Random Forest Regression Training Features Show Runs Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Runs button in the side navigation Create Run Instructions Code run = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'linear regression' ) Toggle Paramenters Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Runs button in the side navigation Click the Show Parameters button at the top of the runs table to show parameters for runs Click the Hide Parameters button at the top of the runs table to hide parameters for runs Compare Runs Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Runs button in the side navigation Select the relevant runs by clicking the checkbox Click the Compare button at the top of the runs table Export Runs Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Runs button in the side navigation Select the relevant runs by clicking the checkbox Click the Export button at the top of the runs table","title":"Runs"},{"location":"essentials/runs/#runs","text":"","title":"Runs"},{"location":"essentials/runs/#overview","text":"Runs belong to exactly one project and none, one or many experiments. However, it is good practice to assign a run to at least one experiment. They may have input from previous runs and may generate outputs \u2013 named artifacts \u2013 such as models. Runs also contain parameters and metrics that are key-value pairs to make them comparable. Example Project: House Price Prediction Experiment 1: Linear Regression Run 1: Data Preparation Run 2: Test Train Split Run 3: Linear Regression Training Experiment 2: Random Forest Regression Run 1: Data Preparation Run 2: Test Train Split Run 4: Random Forest Regression Training","title":"Overview"},{"location":"essentials/runs/#features","text":"","title":"Features"},{"location":"essentials/runs/#show-runs","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Runs button in the side navigation","title":"Show Runs"},{"location":"essentials/runs/#create-run","text":"Instructions Code run = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'linear regression' )","title":"Create Run"},{"location":"essentials/runs/#toggle-paramenters","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Runs button in the side navigation Click the Show Parameters button at the top of the runs table to show parameters for runs Click the Hide Parameters button at the top of the runs table to hide parameters for runs","title":"Toggle Paramenters"},{"location":"essentials/runs/#compare-runs","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Runs button in the side navigation Select the relevant runs by clicking the checkbox Click the Compare button at the top of the runs table","title":"Compare Runs"},{"location":"essentials/runs/#export-runs","text":"Instructions GUI Select the relevant project by clicking it in the home view or via the Projects dropdown in the main navigation Click the Runs button in the side navigation Select the relevant runs by clicking the checkbox Click the Export button at the top of the runs table","title":"Export Runs"},{"location":"essentials/users/","text":"Users Overview ML Aide provides internal user management that allows to Update personal information Manage API Keys Features Show User Settings Instructions GUI Click the User name button in the upper right corner to open the user drop-down menu Click the Settings button Update User Profile Instructions GUI Click the User name button in the upper right corner to open the user drop-down menu Click the Settings button Click the Profile button in the side navigation Change First name - optional Last name - optional Nickname Confirm by clicking the Save button Add API Key Instructions GUI Click the User name button in the upper right corner to open the user drop-down menu Click the Settings button Click the API Keys button in the side navigation Click the Add API Key button Provide Description - optional Expires at - optional Confirm by clicking the Create button Use API Key Instructions Code options = ConnectionOptions ( server_url = 'http://localhost:8881/api/v1' , # the ML Aide demo server runs on port 8881 per default api_key = '<your api key>' ) mlaide_client = MLAideClient ( project_key = 'usa-housing' , options = options ) Delete API Key Instructions GUI Click the User name button in the upper right corner to open the user drop-down menu Click the Settings button Click the API Keys button in the side navigation Click the Delete API Key button ( ) for the relevant API key","title":"Users"},{"location":"essentials/users/#users","text":"","title":"Users"},{"location":"essentials/users/#overview","text":"ML Aide provides internal user management that allows to Update personal information Manage API Keys","title":"Overview"},{"location":"essentials/users/#features","text":"","title":"Features"},{"location":"essentials/users/#show-user-settings","text":"Instructions GUI Click the User name button in the upper right corner to open the user drop-down menu Click the Settings button","title":"Show User Settings"},{"location":"essentials/users/#update-user-profile","text":"Instructions GUI Click the User name button in the upper right corner to open the user drop-down menu Click the Settings button Click the Profile button in the side navigation Change First name - optional Last name - optional Nickname Confirm by clicking the Save button","title":"Update User Profile"},{"location":"essentials/users/#add-api-key","text":"Instructions GUI Click the User name button in the upper right corner to open the user drop-down menu Click the Settings button Click the API Keys button in the side navigation Click the Add API Key button Provide Description - optional Expires at - optional Confirm by clicking the Create button","title":"Add API Key"},{"location":"essentials/users/#use-api-key","text":"Instructions Code options = ConnectionOptions ( server_url = 'http://localhost:8881/api/v1' , # the ML Aide demo server runs on port 8881 per default api_key = '<your api key>' ) mlaide_client = MLAideClient ( project_key = 'usa-housing' , options = options )","title":"Use API Key"},{"location":"essentials/users/#delete-api-key","text":"Instructions GUI Click the User name button in the upper right corner to open the user drop-down menu Click the Settings button Click the API Keys button in the side navigation Click the Delete API Key button ( ) for the relevant API key","title":"Delete API Key"},{"location":"start/environment-setup/","text":"Environment Setup Work in Progress","title":"Environment Setup"},{"location":"start/environment-setup/#environment-setup","text":"","title":"Environment Setup"},{"location":"start/environment-setup/#work-in-progress","text":"","title":"Work in Progress"},{"location":"start/quickstart/","text":"Quickstart This quickstart shows how to get ML Aide running in your local environment. This quickstart is only for demo purposes and should not be used for a production setup. ML Aide is shipped with Docker. Therefore you need Docker installed. On Linux, you also have to install Docker Compose . Clone Repo Clone the ML Aide git repository git clone https://github.com/MLAide/MLAide.git For this quickstart, you don't have to compile or build anything. We just need the docker-compose.yaml from the demo/ directory. Prepare Add the following entry to your hosts file, to make sure keycloack can verify the user tokens. The file is located at /etc/hosts (Unix) or C:\\Windows\\System32\\drivers\\etc\\hosts (Windows). 127.0.0.1 keycloak.mlaide On Unix systems, you can use the following command to add the entry to your `hosts file. echo '127.0.0.1 keycloak.mlaide' | sudo tee -a /etc/hosts Start After that start ML Aide from your demo/ folder that is located in the cloned repository using: cd demo docker-compose up Verify Now you should have several containers running: MLAide web user interface MLAide webserver MongoDB which is used by the webserver to store all structured metadata min.io that is used by the webserver to store all artifacts and models keycloak to provide an identity provider, authentication, and authorization Use You can access the Web UI on localhost:8880 with your browser. This demo provides three pre-defined users: adam (password = adam1, email = adam@demo.mlaide.com) bob (password = bob1, email = bob@demo.mlaide.com) eve (password = eve1, email = eve@demo.mlaide.com) Using the Python client To track your machine learning runs you can use the Python client. Start the Tutorial for your first steps.","title":"Quickstart"},{"location":"start/quickstart/#quickstart","text":"This quickstart shows how to get ML Aide running in your local environment. This quickstart is only for demo purposes and should not be used for a production setup. ML Aide is shipped with Docker. Therefore you need Docker installed. On Linux, you also have to install Docker Compose .","title":"Quickstart"},{"location":"start/quickstart/#clone-repo","text":"Clone the ML Aide git repository git clone https://github.com/MLAide/MLAide.git For this quickstart, you don't have to compile or build anything. We just need the docker-compose.yaml from the demo/ directory.","title":"Clone Repo"},{"location":"start/quickstart/#prepare","text":"Add the following entry to your hosts file, to make sure keycloack can verify the user tokens. The file is located at /etc/hosts (Unix) or C:\\Windows\\System32\\drivers\\etc\\hosts (Windows). 127.0.0.1 keycloak.mlaide On Unix systems, you can use the following command to add the entry to your `hosts file. echo '127.0.0.1 keycloak.mlaide' | sudo tee -a /etc/hosts","title":"Prepare"},{"location":"start/quickstart/#start","text":"After that start ML Aide from your demo/ folder that is located in the cloned repository using: cd demo docker-compose up","title":"Start"},{"location":"start/quickstart/#verify","text":"Now you should have several containers running: MLAide web user interface MLAide webserver MongoDB which is used by the webserver to store all structured metadata min.io that is used by the webserver to store all artifacts and models keycloak to provide an identity provider, authentication, and authorization","title":"Verify"},{"location":"start/quickstart/#use","text":"You can access the Web UI on localhost:8880 with your browser. This demo provides three pre-defined users: adam (password = adam1, email = adam@demo.mlaide.com) bob (password = bob1, email = bob@demo.mlaide.com) eve (password = eve1, email = eve@demo.mlaide.com)","title":"Use"},{"location":"start/quickstart/#using-the-python-client","text":"To track your machine learning runs you can use the Python client. Start the Tutorial for your first steps.","title":"Using the Python client"},{"location":"tutorial/data-preparation/","text":"Data Preparation In this chapter, we will load and prepare the USA Housing dataset . All steps that we execute will be stored in ML Aide. Download required Dataset First, download the dataset and save it in a subdirectory called data . mkdir data curl https://raw.githubusercontent.com/MLAide/docs/master/docs/tutorial/housing.csv --output ./data/housing.csv Create connection to ML Aide webserver Our data preparation will be implemented in data_preparation.py . Therefore create a new file with this name. At the top we need some imports and the connection as described in the previous step : from mlaide import MLAideClient , ConnectionOptions import pandas as pd options = ConnectionOptions ( server_url = 'http://localhost:8881/api/v1' , # the ML Aide demo server runs on port 8881 per default api_key = '<your api key>' ) mlaide_client = MLAideClient ( project_key = 'usa-housing' , options = options ) Create Run Before we read or process anything we should start tracking all relevant information in ML Aide. In ML Aide a run is the key concept to track parameters, metrics, artifacts and models. All runs belong to one or more experiments . run_data_preparation = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'data preparation' ) Now we can read and process this dataset. Also, we can register the dataset as an artifact in ML Aide. This gives us the ability to reproduce the following steps - even if the dataset is lost, deleted, or modified. The artifact can be used in other runs as an input. This helps to track down the lineage of a machine learning model to its root. In the end, don't forget to mark the run as completed. housing_data = pd . read_csv ( 'data/housing.csv' ) # add dataset as artifact artifact = run_data_preparation . create_artifact ( name = \"USA housing dataset\" , artifact_type = \"dataset\" , metadata = {}) run_data_preparation . add_artifact_file ( artifact , 'data/housing.csv' ) run_data_preparation . set_completed_status () Start your python script using your shell with python data_preparation.py . After the script completed check the web UI to see the created run and the artifact. Summary In this chapter we created our first run in ML Aide attached the dataset as an artifact to the run Your code should look like the following snippet shows. Code data_preparation.py from mlaide import MLAideClient , ConnectionOptions import pandas as pd options = ConnectionOptions ( server_url = 'http://localhost:8881/api/v1' , # the ML Aide demo server runs on port 8881 per default api_key = '<your api key>' ) mlaide_client = MLAideClient ( project_key = 'usa-housing' , options = options ) run_data_preparation = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'data preparation' ) housing_data = pd . read_csv ( 'data/housing.csv' ) # add dataset as artifact artifact = run_data_preparation . create_artifact ( name = \"USA housing dataset\" , artifact_type = \"dataset\" , metadata = {}) run_data_preparation . add_artifact_file ( artifact , 'data/housing.csv' ) run_data_preparation . set_completed_status () data/housing.csv a lot of housing data The next step is to create a model based on this dataset.","title":"Data Preparation"},{"location":"tutorial/data-preparation/#data-preparation","text":"In this chapter, we will load and prepare the USA Housing dataset . All steps that we execute will be stored in ML Aide.","title":"Data Preparation"},{"location":"tutorial/data-preparation/#download-required-dataset","text":"First, download the dataset and save it in a subdirectory called data . mkdir data curl https://raw.githubusercontent.com/MLAide/docs/master/docs/tutorial/housing.csv --output ./data/housing.csv","title":"Download required Dataset"},{"location":"tutorial/data-preparation/#create-connection-to-ml-aide-webserver","text":"Our data preparation will be implemented in data_preparation.py . Therefore create a new file with this name. At the top we need some imports and the connection as described in the previous step : from mlaide import MLAideClient , ConnectionOptions import pandas as pd options = ConnectionOptions ( server_url = 'http://localhost:8881/api/v1' , # the ML Aide demo server runs on port 8881 per default api_key = '<your api key>' ) mlaide_client = MLAideClient ( project_key = 'usa-housing' , options = options )","title":"Create connection to ML Aide webserver"},{"location":"tutorial/data-preparation/#create-run","text":"Before we read or process anything we should start tracking all relevant information in ML Aide. In ML Aide a run is the key concept to track parameters, metrics, artifacts and models. All runs belong to one or more experiments . run_data_preparation = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'data preparation' ) Now we can read and process this dataset. Also, we can register the dataset as an artifact in ML Aide. This gives us the ability to reproduce the following steps - even if the dataset is lost, deleted, or modified. The artifact can be used in other runs as an input. This helps to track down the lineage of a machine learning model to its root. In the end, don't forget to mark the run as completed. housing_data = pd . read_csv ( 'data/housing.csv' ) # add dataset as artifact artifact = run_data_preparation . create_artifact ( name = \"USA housing dataset\" , artifact_type = \"dataset\" , metadata = {}) run_data_preparation . add_artifact_file ( artifact , 'data/housing.csv' ) run_data_preparation . set_completed_status () Start your python script using your shell with python data_preparation.py . After the script completed check the web UI to see the created run and the artifact.","title":"Create Run"},{"location":"tutorial/data-preparation/#summary","text":"In this chapter we created our first run in ML Aide attached the dataset as an artifact to the run Your code should look like the following snippet shows. Code data_preparation.py from mlaide import MLAideClient , ConnectionOptions import pandas as pd options = ConnectionOptions ( server_url = 'http://localhost:8881/api/v1' , # the ML Aide demo server runs on port 8881 per default api_key = '<your api key>' ) mlaide_client = MLAideClient ( project_key = 'usa-housing' , options = options ) run_data_preparation = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'data preparation' ) housing_data = pd . read_csv ( 'data/housing.csv' ) # add dataset as artifact artifact = run_data_preparation . create_artifact ( name = \"USA housing dataset\" , artifact_type = \"dataset\" , metadata = {}) run_data_preparation . add_artifact_file ( artifact , 'data/housing.csv' ) run_data_preparation . set_completed_status () data/housing.csv a lot of housing data The next step is to create a model based on this dataset.","title":"Summary"},{"location":"tutorial/introduction/","text":"Introduction In this tutorial, we will use the USA Housing dataset to predict the prices of houses in Boston. To keep things simple for this tutorial we won't use Jupyter Notebooks. Instead, we write just simple Python code. We will use the dataset to train some machine learning models. All processed data and all experiments should be tracked in ML Aide. We also want to store the trained models in ML Aide for later usage. To get started we need some initial work to be done.","title":"Introduction"},{"location":"tutorial/introduction/#introduction","text":"In this tutorial, we will use the USA Housing dataset to predict the prices of houses in Boston. To keep things simple for this tutorial we won't use Jupyter Notebooks. Instead, we write just simple Python code. We will use the dataset to train some machine learning models. All processed data and all experiments should be tracked in ML Aide. We also want to store the trained models in ML Aide for later usage. To get started we need some initial work to be done.","title":"Introduction"},{"location":"tutorial/model-evaluation/","text":"Model Evaluation Compare runs A key feature of ML Aide is to compare several runs with their parameters and metrics. Therefore open the web UI and select all runs that should be compared. In this case, we want to compare linear regression and lasso model . Select the two checkboxes and click on the Compare button at the top of the table. You will see all parameters and metrics of the two runs. All values that are not equal will be highlighted. Visualize Lineage Sometimes you want to know how a model was built or which runs (steps) were executed in a particular experiment. For this, you can use the lineage visualization of experiments. Go to the experiment view and select an experiment. You will see all runs (blue color) and all input/output artifacts (red color). The table below shows you all runs and artifacts. From the runs table, you can jump the run details or to the run comparison.","title":"Model Evaluation"},{"location":"tutorial/model-evaluation/#model-evaluation","text":"","title":"Model Evaluation"},{"location":"tutorial/model-evaluation/#compare-runs","text":"A key feature of ML Aide is to compare several runs with their parameters and metrics. Therefore open the web UI and select all runs that should be compared. In this case, we want to compare linear regression and lasso model . Select the two checkboxes and click on the Compare button at the top of the table. You will see all parameters and metrics of the two runs. All values that are not equal will be highlighted.","title":"Compare runs"},{"location":"tutorial/model-evaluation/#visualize-lineage","text":"Sometimes you want to know how a model was built or which runs (steps) were executed in a particular experiment. For this, you can use the lineage visualization of experiments. Go to the experiment view and select an experiment. You will see all runs (blue color) and all input/output artifacts (red color). The table below shows you all runs and artifacts. From the runs table, you can jump the run details or to the run comparison.","title":"Visualize Lineage"},{"location":"tutorial/model-training/","text":"Model Training In the last chapter we loaded the USA Housing dataset. Now we will train two different models on this dataset. All details of the training will be tracked in ML Aide. Create connection to ML Aide webserver Our code will be written in a new file named training.py . In the beginning we will create a connection to the ML Aide webserver. from mlaide import MLAideClient , ConnectionOptions , ArtifactRef import pandas as pd import numpy as np from sklearn.model_selection import cross_val_score , train_test_split from sklearn.pipeline import Pipeline from sklearn.preprocessing import StandardScaler from sklearn.linear_model import LinearRegression , Lasso from sklearn import metrics options = ConnectionOptions ( server_url = 'http://localhost:8881/api/v1' , # the ML Aide demo server runs on port 8881 per default api_key = '<your api key>' ) mlaide_client = MLAideClient ( project_key = 'usa-housing' , options = options ) Train Test Split As you can see we are implementing these steps in a different file as the data preprocessing. Therefore we somehow need to get our input data. We could read the CSV again. Or we could retrieve the CSV file from ML Aide. In this case we will read the content of the file from ML Aide. In the previous step we saved the file as an artifact with the name USA housing dataset . Ommiting the version means that we want to retrieve the latest version of the artifact. dataset_bytes = mlaide_client . get_artifact ( 'USA housing dataset' , version = None ) . load ( 'data/housing.csv' ) housing_data = pd . read_csv ( dataset_bytes ) Usually a split will be done randomly. ML Aide helps you to keep things reproducible. We start a new run to track the split. Also, we set the dataset as an input artifact. artifact_ref = ArtifactRef ( name = \"USA housing dataset\" , version = 1 ) run_pipeline_setup = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'pipeline setup' , used_artifacts = [ artifact_ref ]) Now we split our dataset and link all information related to the split to our run. In this case we want to track all arguments ( test_size and random_state ) of the train_test_split() function. X = housing_data [[ 'Avg. Area Income' , 'Avg. Area House Age' , 'Avg. Area Number of Rooms' , 'Avg. Area Number of Bedrooms' , 'Area Population' ]] y = housing_data [ 'Price' ] test_size = 0.3 random_state = 42 X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = test_size , random_state = random_state ) run_pipeline_setup . log_parameter ( 'test_size' , test_size ) run_pipeline_setup . log_parameter ( 'random_state' , random_state ) If you have a close look at the data, you can see that all X values must be scaled, before we can use them. We use the StandardScaler of sklearn. The scaler that will be fitted here, must also be used later for predicting new values. ML Aide makes this easy by just storing the scaler (or the whole pipeline) in ML Aide as an artifact. The artifact can be loaded later in a separate process for predicting. pipeline = Pipeline ([ ( 'std_scalar' , StandardScaler ()) ]) X_train = pipeline . fit_transform ( X_train ) X_test = pipeline . transform ( X_test ) run_pipeline_setup . log_model ( pipeline , model_name = \"pipeline\" ) run_pipeline_setup . set_completed_status () Linear Regression After the train-test-split, we can fit a linear regression model. We start a new run and link dataset and the pipeline as input artifacts. dataset_artifact_ref = ArtifactRef ( name = \"USA housing dataset\" , version = 1 ) pipeline_artifact_ref = ArtifactRef ( name = \"pipeline\" , version = 1 ) run_linear_regression = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'linear regression' , used_artifacts = [ dataset_artifact_ref , pipeline_artifact_ref ]) Now just fit your model as usual. After that, you can log the model with log_model() in ML Aide. lin_reg = LinearRegression ( normalize = True ) lin_reg . fit ( X_train , y_train ) run_linear_regression . log_model ( lin_reg , 'linear regression' ) Finally, we calculate some model metrics. The metrics will also be tracked in ML Aide. test_pred = lin_reg . predict ( X_test ) train_pred = lin_reg . predict ( X_train ) mae = metrics . mean_absolute_error ( y_test , test_pred ) mse = metrics . mean_squared_error ( y_test , test_pred ) rmse = np . sqrt ( metrics . mean_squared_error ( y_test , test_pred )) r2 = metrics . r2_score ( y_test , test_pred ) cross_validation = cross_val_score ( LinearRegression (), X , y , cv = 10 ) . mean () run_linear_regression . log_metric ( 'mae' , mae ) run_linear_regression . log_metric ( 'mse' , mse ) run_linear_regression . log_metric ( 'rmse' , rmse ) run_linear_regression . log_metric ( 'r2' , r2 ) run_linear_regression . log_metric ( 'cross validation' , cross_validation ) run_linear_regression . set_completed_status () Lasso Regression Until now, we created three runs ( data preparation , pipeline setup , and linear regression ). All of these runs belong to the experiment linear-regression . Now we train another model type - a lasso regression model. But we want to reuse the results of the data preparation and the pipeline setup. With ML Aide this can be achieved simply by using a new experiment_key and provide the artifacts of the previous runs via used_artifacts . dataset_artifact_ref = ArtifactRef ( name = \"USA housing dataset\" , version = 1 ) pipeline_artifact_ref = ArtifactRef ( name = \"pipeline\" , version = 1 ) run_lasso = mlaide_client . start_new_run ( experiment_key = 'lasso-regression' , run_name = 'lasso regression' , used_artifacts = [ dataset_artifact_ref , pipeline_artifact_ref ]) We fit our model as usual. alpha = 0.1 precompute = True positive = True selection = 'random' random_state = 42 run_lasso . log_parameter ( 'alpha' , alpha ) run_lasso . log_parameter ( 'precompute' , precompute ) run_lasso . log_parameter ( 'positive' , positive ) run_lasso . log_parameter ( 'selection' , selection ) run_lasso . log_parameter ( 'random state' , random_state ) model = Lasso ( alpha = alpha , precompute = precompute , positive = positive , selection = selection , random_state = random_state ) model . fit ( X_train , y_train ) run_lasso . log_model ( model , 'lasso' ) And now we calculate some metrics for this model, too. test_pred = model . predict ( X_test ) train_pred = model . predict ( X_train ) mae = metrics . mean_absolute_error ( y_test , test_pred ) mse = metrics . mean_squared_error ( y_test , test_pred ) rmse = np . sqrt ( metrics . mean_squared_error ( y_test , test_pred )) r2 = metrics . r2_score ( y_test , test_pred ) cross_validation = cross_val_score ( Lasso (), X , y , cv = 10 ) . mean () run_lasso . log_metric ( 'mae' , mae ) run_lasso . log_metric ( 'mse' , mse ) run_lasso . log_metric ( 'rmse' , rmse ) run_lasso . log_metric ( 'r2' , r2 ) run_lasso . log_metric ( 'cross validation' , cross_validation ) run_lasso . set_completed_status () Start your python script using your shell with python training.py . After the script completed check the Web UI to see the created runs and the artifact. Summary In this chapter we created a sklearn pipeline with a standard scaler trained a linear regression model trained a lasso regression model All these steps were tracked in ML Aide as separate runs. The runs included all parameters and metrics that we need for reproducibility and further investigation. The pipeline and the models are stored as artifacts in ML Aide. Your code should look like the following snippet shows. Code training.py from mlaide import MLAideClient , ConnectionOptions , ArtifactRef import pandas as pd import numpy as np from sklearn.model_selection import cross_val_score , train_test_split from sklearn.pipeline import Pipeline from sklearn.preprocessing import StandardScaler from sklearn.linear_model import LinearRegression , Lasso from sklearn import metrics # create connection options = ConnectionOptions ( server_url = 'http://localhost:8881/api/v1' , # the ML Aide demo server runs on port 8881 per default api_key = '<your api key>' ) mlaide_client = MLAideClient ( project_key = 'usa-housing' , options = options ) # get housing dataset dataset_bytes = mlaide_client . get_artifact ( 'USA housing dataset' , version = None ) . load ( 'data/housing.csv' ) housing_data = pd . read_csv ( dataset_bytes ) artifact_ref = ArtifactRef ( name = \"USA housing dataset\" , version = 1 ) run_pipeline_setup = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'pipeline setup' , used_artifacts = [ artifact_ref ]) # train test split X = housing_data [[ 'Avg. Area Income' , 'Avg. Area House Age' , 'Avg. Area Number of Rooms' , 'Avg. Area Number of Bedrooms' , 'Area Population' ]] y = housing_data [ 'Price' ] test_size = 0.3 random_state = 42 X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = test_size , random_state = random_state ) run_pipeline_setup . log_parameter ( 'test_size' , test_size ) run_pipeline_setup . log_parameter ( 'random_state' , random_state ) pipeline = Pipeline ([ ( 'std_scalar' , StandardScaler ()) ]) X_train = pipeline . fit_transform ( X_train ) X_test = pipeline . transform ( X_test ) run_pipeline_setup . log_model ( pipeline , model_name = \"pipeline\" ) run_pipeline_setup . set_completed_status () # linear regression dataset_artifact_ref = ArtifactRef ( name = \"USA housing dataset\" , version = 1 ) pipeline_artifact_ref = ArtifactRef ( name = \"pipeline\" , version = 1 ) run_linear_regression = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'linear regression' , used_artifacts = [ dataset_artifact_ref , pipeline_artifact_ref ]) lin_reg = LinearRegression ( normalize = True ) lin_reg . fit ( X_train , y_train ) run_linear_regression . log_model ( lin_reg , 'linear regression' ) test_pred = lin_reg . predict ( X_test ) train_pred = lin_reg . predict ( X_train ) mae = metrics . mean_absolute_error ( y_test , test_pred ) mse = metrics . mean_squared_error ( y_test , test_pred ) rmse = np . sqrt ( metrics . mean_squared_error ( y_test , test_pred )) r2 = metrics . r2_score ( y_test , test_pred ) cross_validation = cross_val_score ( LinearRegression (), X , y , cv = 10 ) . mean () run_linear_regression . log_metric ( 'mae' , mae ) run_linear_regression . log_metric ( 'mse' , mse ) run_linear_regression . log_metric ( 'rmse' , rmse ) run_linear_regression . log_metric ( 'r2' , r2 ) run_linear_regression . log_metric ( 'cross validation' , cross_validation ) run_linear_regression . set_completed_status () # lasso regression dataset_artifact_ref = ArtifactRef ( name = \"USA housing dataset\" , version = 1 ) pipeline_artifact_ref = ArtifactRef ( name = \"pipeline\" , version = 1 ) run_lasso = mlaide_client . start_new_run ( experiment_key = 'lasso-regression' , run_name = 'lasso regression' , used_artifacts = [ dataset_artifact_ref , pipeline_artifact_ref ]) alpha = 0.1 precompute = True positive = True selection = 'random' random_state = 42 run_lasso . log_parameter ( 'alpha' , alpha ) run_lasso . log_parameter ( 'precompute' , precompute ) run_lasso . log_parameter ( 'positive' , positive ) run_lasso . log_parameter ( 'selection' , selection ) run_lasso . log_parameter ( 'random state' , random_state ) model = Lasso ( alpha = alpha , precompute = precompute , positive = positive , selection = selection , random_state = random_state ) model . fit ( X_train , y_train ) run_lasso . log_model ( model , 'lasso' ) test_pred = model . predict ( X_test ) train_pred = model . predict ( X_train ) mae = metrics . mean_absolute_error ( y_test , test_pred ) mse = metrics . mean_squared_error ( y_test , test_pred ) rmse = np . sqrt ( metrics . mean_squared_error ( y_test , test_pred )) r2 = metrics . r2_score ( y_test , test_pred ) cross_validation = cross_val_score ( Lasso (), X , y , cv = 10 ) . mean () run_lasso . log_metric ( 'mae' , mae ) run_lasso . log_metric ( 'mse' , mse ) run_lasso . log_metric ( 'rmse' , rmse ) run_lasso . log_metric ( 'r2' , r2 ) run_lasso . log_metric ( 'cross validation' , cross_validation ) run_lasso . set_completed_status () data_preparation.py from mlaide import MLAideClient , ConnectionOptions import pandas as pd options = ConnectionOptions ( server_url = 'http://localhost:8881/api/v1' , # the ML Aide demo server runs on port 8881 per default api_key = '<your api key>' ) mlaide_client = MLAideClient ( project_key = 'usa-housing' , options = options ) run_data_preparation = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'data preparation' ) housing_data = pd . read_csv ( 'data/housing.csv' ) # add dataset as artifact artifact = run_data_preparation . create_artifact ( name = \"USA housing dataset\" , artifact_type = \"dataset\" , metadata = {}) run_data_preparation . add_artifact_file ( artifact , 'data/housing.csv' ) run_data_preparation . set_completed_status () data/housing.csv a lot of housing data In the next chapter, we will learn how to evaluate models with ML Aide.","title":"Model Training"},{"location":"tutorial/model-training/#model-training","text":"In the last chapter we loaded the USA Housing dataset. Now we will train two different models on this dataset. All details of the training will be tracked in ML Aide.","title":"Model Training"},{"location":"tutorial/model-training/#create-connection-to-ml-aide-webserver","text":"Our code will be written in a new file named training.py . In the beginning we will create a connection to the ML Aide webserver. from mlaide import MLAideClient , ConnectionOptions , ArtifactRef import pandas as pd import numpy as np from sklearn.model_selection import cross_val_score , train_test_split from sklearn.pipeline import Pipeline from sklearn.preprocessing import StandardScaler from sklearn.linear_model import LinearRegression , Lasso from sklearn import metrics options = ConnectionOptions ( server_url = 'http://localhost:8881/api/v1' , # the ML Aide demo server runs on port 8881 per default api_key = '<your api key>' ) mlaide_client = MLAideClient ( project_key = 'usa-housing' , options = options )","title":"Create connection to ML Aide webserver"},{"location":"tutorial/model-training/#train-test-split","text":"As you can see we are implementing these steps in a different file as the data preprocessing. Therefore we somehow need to get our input data. We could read the CSV again. Or we could retrieve the CSV file from ML Aide. In this case we will read the content of the file from ML Aide. In the previous step we saved the file as an artifact with the name USA housing dataset . Ommiting the version means that we want to retrieve the latest version of the artifact. dataset_bytes = mlaide_client . get_artifact ( 'USA housing dataset' , version = None ) . load ( 'data/housing.csv' ) housing_data = pd . read_csv ( dataset_bytes ) Usually a split will be done randomly. ML Aide helps you to keep things reproducible. We start a new run to track the split. Also, we set the dataset as an input artifact. artifact_ref = ArtifactRef ( name = \"USA housing dataset\" , version = 1 ) run_pipeline_setup = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'pipeline setup' , used_artifacts = [ artifact_ref ]) Now we split our dataset and link all information related to the split to our run. In this case we want to track all arguments ( test_size and random_state ) of the train_test_split() function. X = housing_data [[ 'Avg. Area Income' , 'Avg. Area House Age' , 'Avg. Area Number of Rooms' , 'Avg. Area Number of Bedrooms' , 'Area Population' ]] y = housing_data [ 'Price' ] test_size = 0.3 random_state = 42 X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = test_size , random_state = random_state ) run_pipeline_setup . log_parameter ( 'test_size' , test_size ) run_pipeline_setup . log_parameter ( 'random_state' , random_state ) If you have a close look at the data, you can see that all X values must be scaled, before we can use them. We use the StandardScaler of sklearn. The scaler that will be fitted here, must also be used later for predicting new values. ML Aide makes this easy by just storing the scaler (or the whole pipeline) in ML Aide as an artifact. The artifact can be loaded later in a separate process for predicting. pipeline = Pipeline ([ ( 'std_scalar' , StandardScaler ()) ]) X_train = pipeline . fit_transform ( X_train ) X_test = pipeline . transform ( X_test ) run_pipeline_setup . log_model ( pipeline , model_name = \"pipeline\" ) run_pipeline_setup . set_completed_status ()","title":"Train Test Split"},{"location":"tutorial/model-training/#linear-regression","text":"After the train-test-split, we can fit a linear regression model. We start a new run and link dataset and the pipeline as input artifacts. dataset_artifact_ref = ArtifactRef ( name = \"USA housing dataset\" , version = 1 ) pipeline_artifact_ref = ArtifactRef ( name = \"pipeline\" , version = 1 ) run_linear_regression = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'linear regression' , used_artifacts = [ dataset_artifact_ref , pipeline_artifact_ref ]) Now just fit your model as usual. After that, you can log the model with log_model() in ML Aide. lin_reg = LinearRegression ( normalize = True ) lin_reg . fit ( X_train , y_train ) run_linear_regression . log_model ( lin_reg , 'linear regression' ) Finally, we calculate some model metrics. The metrics will also be tracked in ML Aide. test_pred = lin_reg . predict ( X_test ) train_pred = lin_reg . predict ( X_train ) mae = metrics . mean_absolute_error ( y_test , test_pred ) mse = metrics . mean_squared_error ( y_test , test_pred ) rmse = np . sqrt ( metrics . mean_squared_error ( y_test , test_pred )) r2 = metrics . r2_score ( y_test , test_pred ) cross_validation = cross_val_score ( LinearRegression (), X , y , cv = 10 ) . mean () run_linear_regression . log_metric ( 'mae' , mae ) run_linear_regression . log_metric ( 'mse' , mse ) run_linear_regression . log_metric ( 'rmse' , rmse ) run_linear_regression . log_metric ( 'r2' , r2 ) run_linear_regression . log_metric ( 'cross validation' , cross_validation ) run_linear_regression . set_completed_status ()","title":"Linear Regression"},{"location":"tutorial/model-training/#lasso-regression","text":"Until now, we created three runs ( data preparation , pipeline setup , and linear regression ). All of these runs belong to the experiment linear-regression . Now we train another model type - a lasso regression model. But we want to reuse the results of the data preparation and the pipeline setup. With ML Aide this can be achieved simply by using a new experiment_key and provide the artifacts of the previous runs via used_artifacts . dataset_artifact_ref = ArtifactRef ( name = \"USA housing dataset\" , version = 1 ) pipeline_artifact_ref = ArtifactRef ( name = \"pipeline\" , version = 1 ) run_lasso = mlaide_client . start_new_run ( experiment_key = 'lasso-regression' , run_name = 'lasso regression' , used_artifacts = [ dataset_artifact_ref , pipeline_artifact_ref ]) We fit our model as usual. alpha = 0.1 precompute = True positive = True selection = 'random' random_state = 42 run_lasso . log_parameter ( 'alpha' , alpha ) run_lasso . log_parameter ( 'precompute' , precompute ) run_lasso . log_parameter ( 'positive' , positive ) run_lasso . log_parameter ( 'selection' , selection ) run_lasso . log_parameter ( 'random state' , random_state ) model = Lasso ( alpha = alpha , precompute = precompute , positive = positive , selection = selection , random_state = random_state ) model . fit ( X_train , y_train ) run_lasso . log_model ( model , 'lasso' ) And now we calculate some metrics for this model, too. test_pred = model . predict ( X_test ) train_pred = model . predict ( X_train ) mae = metrics . mean_absolute_error ( y_test , test_pred ) mse = metrics . mean_squared_error ( y_test , test_pred ) rmse = np . sqrt ( metrics . mean_squared_error ( y_test , test_pred )) r2 = metrics . r2_score ( y_test , test_pred ) cross_validation = cross_val_score ( Lasso (), X , y , cv = 10 ) . mean () run_lasso . log_metric ( 'mae' , mae ) run_lasso . log_metric ( 'mse' , mse ) run_lasso . log_metric ( 'rmse' , rmse ) run_lasso . log_metric ( 'r2' , r2 ) run_lasso . log_metric ( 'cross validation' , cross_validation ) run_lasso . set_completed_status () Start your python script using your shell with python training.py . After the script completed check the Web UI to see the created runs and the artifact.","title":"Lasso Regression"},{"location":"tutorial/model-training/#summary","text":"In this chapter we created a sklearn pipeline with a standard scaler trained a linear regression model trained a lasso regression model All these steps were tracked in ML Aide as separate runs. The runs included all parameters and metrics that we need for reproducibility and further investigation. The pipeline and the models are stored as artifacts in ML Aide. Your code should look like the following snippet shows. Code training.py from mlaide import MLAideClient , ConnectionOptions , ArtifactRef import pandas as pd import numpy as np from sklearn.model_selection import cross_val_score , train_test_split from sklearn.pipeline import Pipeline from sklearn.preprocessing import StandardScaler from sklearn.linear_model import LinearRegression , Lasso from sklearn import metrics # create connection options = ConnectionOptions ( server_url = 'http://localhost:8881/api/v1' , # the ML Aide demo server runs on port 8881 per default api_key = '<your api key>' ) mlaide_client = MLAideClient ( project_key = 'usa-housing' , options = options ) # get housing dataset dataset_bytes = mlaide_client . get_artifact ( 'USA housing dataset' , version = None ) . load ( 'data/housing.csv' ) housing_data = pd . read_csv ( dataset_bytes ) artifact_ref = ArtifactRef ( name = \"USA housing dataset\" , version = 1 ) run_pipeline_setup = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'pipeline setup' , used_artifacts = [ artifact_ref ]) # train test split X = housing_data [[ 'Avg. Area Income' , 'Avg. Area House Age' , 'Avg. Area Number of Rooms' , 'Avg. Area Number of Bedrooms' , 'Area Population' ]] y = housing_data [ 'Price' ] test_size = 0.3 random_state = 42 X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = test_size , random_state = random_state ) run_pipeline_setup . log_parameter ( 'test_size' , test_size ) run_pipeline_setup . log_parameter ( 'random_state' , random_state ) pipeline = Pipeline ([ ( 'std_scalar' , StandardScaler ()) ]) X_train = pipeline . fit_transform ( X_train ) X_test = pipeline . transform ( X_test ) run_pipeline_setup . log_model ( pipeline , model_name = \"pipeline\" ) run_pipeline_setup . set_completed_status () # linear regression dataset_artifact_ref = ArtifactRef ( name = \"USA housing dataset\" , version = 1 ) pipeline_artifact_ref = ArtifactRef ( name = \"pipeline\" , version = 1 ) run_linear_regression = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'linear regression' , used_artifacts = [ dataset_artifact_ref , pipeline_artifact_ref ]) lin_reg = LinearRegression ( normalize = True ) lin_reg . fit ( X_train , y_train ) run_linear_regression . log_model ( lin_reg , 'linear regression' ) test_pred = lin_reg . predict ( X_test ) train_pred = lin_reg . predict ( X_train ) mae = metrics . mean_absolute_error ( y_test , test_pred ) mse = metrics . mean_squared_error ( y_test , test_pred ) rmse = np . sqrt ( metrics . mean_squared_error ( y_test , test_pred )) r2 = metrics . r2_score ( y_test , test_pred ) cross_validation = cross_val_score ( LinearRegression (), X , y , cv = 10 ) . mean () run_linear_regression . log_metric ( 'mae' , mae ) run_linear_regression . log_metric ( 'mse' , mse ) run_linear_regression . log_metric ( 'rmse' , rmse ) run_linear_regression . log_metric ( 'r2' , r2 ) run_linear_regression . log_metric ( 'cross validation' , cross_validation ) run_linear_regression . set_completed_status () # lasso regression dataset_artifact_ref = ArtifactRef ( name = \"USA housing dataset\" , version = 1 ) pipeline_artifact_ref = ArtifactRef ( name = \"pipeline\" , version = 1 ) run_lasso = mlaide_client . start_new_run ( experiment_key = 'lasso-regression' , run_name = 'lasso regression' , used_artifacts = [ dataset_artifact_ref , pipeline_artifact_ref ]) alpha = 0.1 precompute = True positive = True selection = 'random' random_state = 42 run_lasso . log_parameter ( 'alpha' , alpha ) run_lasso . log_parameter ( 'precompute' , precompute ) run_lasso . log_parameter ( 'positive' , positive ) run_lasso . log_parameter ( 'selection' , selection ) run_lasso . log_parameter ( 'random state' , random_state ) model = Lasso ( alpha = alpha , precompute = precompute , positive = positive , selection = selection , random_state = random_state ) model . fit ( X_train , y_train ) run_lasso . log_model ( model , 'lasso' ) test_pred = model . predict ( X_test ) train_pred = model . predict ( X_train ) mae = metrics . mean_absolute_error ( y_test , test_pred ) mse = metrics . mean_squared_error ( y_test , test_pred ) rmse = np . sqrt ( metrics . mean_squared_error ( y_test , test_pred )) r2 = metrics . r2_score ( y_test , test_pred ) cross_validation = cross_val_score ( Lasso (), X , y , cv = 10 ) . mean () run_lasso . log_metric ( 'mae' , mae ) run_lasso . log_metric ( 'mse' , mse ) run_lasso . log_metric ( 'rmse' , rmse ) run_lasso . log_metric ( 'r2' , r2 ) run_lasso . log_metric ( 'cross validation' , cross_validation ) run_lasso . set_completed_status () data_preparation.py from mlaide import MLAideClient , ConnectionOptions import pandas as pd options = ConnectionOptions ( server_url = 'http://localhost:8881/api/v1' , # the ML Aide demo server runs on port 8881 per default api_key = '<your api key>' ) mlaide_client = MLAideClient ( project_key = 'usa-housing' , options = options ) run_data_preparation = mlaide_client . start_new_run ( experiment_key = 'linear-regression' , run_name = 'data preparation' ) housing_data = pd . read_csv ( 'data/housing.csv' ) # add dataset as artifact artifact = run_data_preparation . create_artifact ( name = \"USA housing dataset\" , artifact_type = \"dataset\" , metadata = {}) run_data_preparation . add_artifact_file ( artifact , 'data/housing.csv' ) run_data_preparation . set_completed_status () data/housing.csv a lot of housing data In the next chapter, we will learn how to evaluate models with ML Aide.","title":"Summary"},{"location":"tutorial/productionize-model/","text":"Productionize Model Work in Progress","title":"Productionize Model"},{"location":"tutorial/productionize-model/#productionize-model","text":"","title":"Productionize Model"},{"location":"tutorial/productionize-model/#work-in-progress","text":"","title":"Work in Progress"},{"location":"tutorial/setup/","text":"Setup Before we start the actual work, we need to set up our project. Run ML Aide For this tutorial, ML Aide server and web-UI are required. The quickstart helps to get ML Aide running. Create a workspace directory In this tutorial, we will use ~/mlaide-tutorial/ as our working directory. Install dependencies via pip Open a terminal in the working directory and install all dependencies. cd ~/mlaide-tutorial pip install scikit-learn pandas mlaide Create ML Aide project Open the ML Aide web UI on localhost:8880 Login as adam (username = adam ; password = adam1 ) Click on Add Project to create a new project - enter USA Housing as project name Create an API key Later, we want to send all parameters, metrics, and models of our experiments to ML Aide. Therefore, we need to set an API key in our python client. Otherwise, we won't be able to authenticate against the ML Aide server. In the upper right click on adam > Settings Go to API Keys in the left navigation Click on Add API Key Enter any description and click on Create Copy the show API key and store it somewhere safe. The API key won't be shown again. If you lose your API key you have to create a new one. Create Connection To create a connection to the ML Aide webserver with Python clients you have to use mlaide.MLAideClient . An object of this class is the main entry point for all kinds of operations. from mlaide import MLAideClient , ConnectionOptions options = ConnectionOptions ( server_url = 'http://localhost:8881/api/v1' , # the ML Aide demo server runs on port 8881 per default api_key = '<your api key>' ) mlaide_client = MLAideClient ( project_key = 'usa-housing' , options = options ) Replace api_key with your personal API key that you created using the ML Aide Web UI. Summary In this chapter we have set up our working environment created our tutorial project created an API key for authorization created a snippet to connect our python client to the ML Aide webserver. Next, we will load and prepare the dataset. Here, we will use the snippet. Now you should have everything up and running to start coding.","title":"Setup"},{"location":"tutorial/setup/#setup","text":"Before we start the actual work, we need to set up our project.","title":"Setup"},{"location":"tutorial/setup/#run-ml-aide","text":"For this tutorial, ML Aide server and web-UI are required. The quickstart helps to get ML Aide running.","title":"Run ML Aide"},{"location":"tutorial/setup/#create-a-workspace-directory","text":"In this tutorial, we will use ~/mlaide-tutorial/ as our working directory.","title":"Create a workspace directory"},{"location":"tutorial/setup/#install-dependencies-via-pip","text":"Open a terminal in the working directory and install all dependencies. cd ~/mlaide-tutorial pip install scikit-learn pandas mlaide","title":"Install dependencies via pip"},{"location":"tutorial/setup/#create-ml-aide-project","text":"Open the ML Aide web UI on localhost:8880 Login as adam (username = adam ; password = adam1 ) Click on Add Project to create a new project - enter USA Housing as project name","title":"Create ML Aide project"},{"location":"tutorial/setup/#create-an-api-key","text":"Later, we want to send all parameters, metrics, and models of our experiments to ML Aide. Therefore, we need to set an API key in our python client. Otherwise, we won't be able to authenticate against the ML Aide server. In the upper right click on adam > Settings Go to API Keys in the left navigation Click on Add API Key Enter any description and click on Create Copy the show API key and store it somewhere safe. The API key won't be shown again. If you lose your API key you have to create a new one.","title":"Create an API key"},{"location":"tutorial/setup/#create-connection","text":"To create a connection to the ML Aide webserver with Python clients you have to use mlaide.MLAideClient . An object of this class is the main entry point for all kinds of operations. from mlaide import MLAideClient , ConnectionOptions options = ConnectionOptions ( server_url = 'http://localhost:8881/api/v1' , # the ML Aide demo server runs on port 8881 per default api_key = '<your api key>' ) mlaide_client = MLAideClient ( project_key = 'usa-housing' , options = options ) Replace api_key with your personal API key that you created using the ML Aide Web UI.","title":"Create Connection"},{"location":"tutorial/setup/#summary","text":"In this chapter we have set up our working environment created our tutorial project created an API key for authorization created a snippet to connect our python client to the ML Aide webserver. Next, we will load and prepare the dataset. Here, we will use the snippet. Now you should have everything up and running to start coding.","title":"Summary"}]}